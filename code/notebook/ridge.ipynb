{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def get_y():\n",
    "    return pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv', usecols=[target]).values.flatten()\n",
    "    \n",
    "def run_extra_tree_model(X_train, y_train, X_valid, y_valid, #X_test\n",
    "                        ):\n",
    "    \n",
    "    model = Ridge(**Ridge_PARAMS)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # train score\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "    # validation score\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    valid_rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "    y_pred_valid = rankdata(y_pred_valid)/len(y_pred_valid)\n",
    "\n",
    "\n",
    "    # predict test\n",
    "    #y_pred_test = model.predict(X_test)\n",
    "    #y_pred_test = rankdata(y_pred_test)/len(y_pred_test)\n",
    "\n",
    "    return y_pred_valid, train_rmse, valid_rmse\n",
    " \n",
    "\n",
    "def to_bins(x, borders):\n",
    "    for i in range(len(borders)):\n",
    "        if x <= borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "class OptimizedRounder_(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -get_score(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [1.5, 2.0, 2.5, 3.0]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(1, 2), (1.5, 2.5), (2, 3), (2.5, 3.5)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -get_score(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [0.2, 0.4, 0.6, 0.8]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(0.01, 0.3), (0.15, 0.56), (0.35, 0.75), (0.6, 0.9)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "class StratifiedGroupKFold():\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        fold = pd.DataFrame([X, y, groups]).T\n",
    "        fold.columns = ['X', 'y', 'groups']\n",
    "        fold['y'] = fold['y'].astype(int)\n",
    "        g = fold.groupby('groups')['y'].agg('mean').reset_index()\n",
    "        fold = fold.merge(g, how='left', on='groups', suffixes=('', '_mean'))\n",
    "        fold['y_mean'] = fold['y_mean'].apply(np.round)\n",
    "        fold['fold_id'] = 0\n",
    "        for unique_y in fold['y_mean'].unique():\n",
    "            mask = fold.y_mean==unique_y\n",
    "            selected = fold[mask].reset_index(drop=True)\n",
    "            cv = GroupKFold(n_splits=n_splits)\n",
    "            for i, (train_index, valid_index) in enumerate(cv.split(range(len(selected)), y=None, groups=selected['groups'])):\n",
    "                selected.loc[valid_index, 'fold_id'] = i\n",
    "            fold.loc[mask, 'fold_id'] = selected['fold_id'].values\n",
    "            \n",
    "        for i in range(self.n_splits):\n",
    "            indices = np.arange(len(fold))\n",
    "            train_index = indices[fold['fold_id'] != i]\n",
    "            valid_index = indices[fold['fold_id'] == i]\n",
    "            yield train_index, valid_index\n",
    "            \n",
    "def merge(train, test, path, add_cols):\n",
    "    df_ = feather.read_dataframe(path)\n",
    "    add_cols += list(df_.columns)\n",
    "    train = pd.concat((train, df_[:len_train]), axis=1)\n",
    "    test = pd.concat((test, df_[len_train:].reset_index(drop=True)), axis=1)\n",
    "    return train, test, add_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'AdoptionSpeed'\n",
    "len_train = 14993\n",
    "len_test = 3948\n",
    "    \n",
    "    \n",
    "# ===============\n",
    "# Params\n",
    "# ===============\n",
    "seed = 777\n",
    "kaeru_seed = 1337\n",
    "n_splits = 5\n",
    "np.random.seed(seed)\n",
    "\n",
    "# feature engineering\n",
    "n_components = 5\n",
    "img_size = 256\n",
    "batch_size = 256\n",
    "\n",
    "# define\n",
    "maxvalue_dict = {}\n",
    "categorical_features = [\n",
    "     'Breed1',\n",
    "     'Breed2',\n",
    "     'Color1',\n",
    "     'Color2',\n",
    "     'Color3',\n",
    "     'Dewormed',\n",
    "     'FurLength',\n",
    "     'Gender',\n",
    "     'Health',\n",
    "     'MaturitySize',\n",
    "     'State',\n",
    "     'Sterilized',\n",
    "     'Type',\n",
    "     'Vaccinated',\n",
    "     'Type_main_breed',\n",
    "     'BreedName_main_breed',\n",
    "     'Type_second_breed',\n",
    "     'BreedName_second_breed',\n",
    "]\n",
    "numerical_features = []\n",
    "text_features = ['Name', 'Description']\n",
    "remove = ['index', 'seq_text', 'PetID', 'Name', 'Description', 'RescuerID', 'StateName', 'annots_top_desc','sentiment_text', \n",
    "          'sentiment_entities', 'Description_Emb', 'Description_bow', 'annots_top_desc_pick']\n",
    "kaeru_drop_cols = [\"2017GDPperCapita\", \"Bumiputra\", \"Chinese\", \"HDI\", \"Indian\", \"Latitude\", \"Longitude\",\n",
    "                   'color_red_score_mean_mean', 'color_red_score_mean_sum', 'color_blue_score_mean_mean',\n",
    "                   'color_blue_score_mean_sum', 'color_green_score_mean_mean', 'color_green_score_mean_sum',\n",
    "                   'dog_cat_scores_mean_mean', 'dog_cat_scores_mean_sum', 'dog_cat_topics_mean_mean',\n",
    "                   'dog_cat_topics_mean_sum', 'is_dog_or_cat_mean_mean', 'is_dog_or_cat_mean_sum',\n",
    "                   'len_text_mean_mean', 'len_text_mean_sum', 'StateID']\n",
    "gege_drop_cols = ['2017GDPperCapita', 'Breed1_equals_Breed2', 'Bumiputra', 'Chinese',\n",
    "                  'HDI', 'Indian','Latitude', 'Longitude', 'Pop_density', 'Urban_pop', 'Breed1_equals_Breed2',\n",
    "                  'fix_Breed1', 'fix_Breed2', 'single_Breed', 'color_red_score_mean_mean', 'color_red_score_mean_sum', \n",
    "                  'color_red_score_mean_var',  'color_blue_score_mean_mean', 'color_blue_score_mean_sum', \n",
    "                   'color_blue_score_mean_var', 'color_green_score_mean_mean', 'color_green_score_mean_sum',\n",
    "                  'color_green_score_mean_var', 'dog_cat_scores_mean_mean', 'dog_cat_scores_mean_sum', \n",
    "                  'dog_cat_scores_mean_var', 'dog_cat_topics_mean_mean', 'dog_cat_topics_mean_sum', \n",
    "                   'dog_cat_topics_mean_var', 'is_dog_or_cat_mean_mean', 'is_dog_or_cat_mean_sum',\n",
    "                  'is_dog_or_cat_mean_var', 'len_text_mean_mean', 'len_text_mean_sum', 'len_text_mean_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "train = feather.read_dataframe('from_kernel/all_datav17.feather')\n",
    "test = train[len_train:]\n",
    "train = train[:len_train]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "predictors = list(set(list(np.load(\"from_kernel/common_colsv17.npy\"))+list(np.load(\"from_kernel/k_colsv17.npy\"))) - set([target] + remove+kaeru_drop_cols))\n",
    "print(len(predictors))\n",
    "categorical_features = [c for c in categorical_features if c in predictors]\n",
    "numerical_features = list(set(predictors) - set(categorical_features + [target] + remove))\n",
    "\n",
    "X_train = train.append(test).reset_index(drop=True).loc[:, predictors]\n",
    "for c in categorical_features:\n",
    "    X_train[c] = LabelEncoder().fit_transform(X_train[c])\n",
    "X_train.replace(np.inf, np.nan, inplace=True)\n",
    "X_train.replace(-np.inf, np.nan, inplace=True)\n",
    "X_train[numerical_features] = StandardScaler().fit_transform(X_train[numerical_features].rank())\n",
    "X_train.fillna(-999, inplace=True)\n",
    "\n",
    "X_test = X_train.iloc[len_train:]\n",
    "X = X_train.iloc[:len_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_PARAMS = {\n",
    "    \"alpha\": 0.1,\n",
    "    \"random_state\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0500820819450583 1.054573030682955\n",
      "1.0398827079014106 1.099548357990164\n",
      "1.0430774623460077 1.0818734858731562\n",
      "1.0460862195514307 1.065654848253104\n",
      "1.0460530955464145 1.0682917685131958\n",
      "0.4021254183486691\n",
      "CPU times: user 19.2 s, sys: 9.36 s, total: 28.5 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y =  feather.read_dataframe('../input/X_train.feather')[\"AdoptionSpeed\"].values\n",
    "rescuer_id = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv').loc[:, 'RescuerID'].iloc[:len_train]\n",
    "\n",
    "y_pred = np.empty(len_train,)\n",
    "y_test = []\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n",
    "#for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y)):\n",
    "#cv = GroupKFold(n_splits=n_splits)\n",
    "#for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y=None, groups=rescuer_id)): \n",
    "cv = StratifiedGroupKFold(n_splits=n_splits)\n",
    "for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y=y, groups=rescuer_id)): \n",
    "    X_train = X.loc[train_index, :]\n",
    "    X_valid = X.loc[valid_index, :]\n",
    "    y_train = y[train_index]\n",
    "    y_valid = y[valid_index]\n",
    "\n",
    "    y_pred_valid, train_rmse, valid_rmse = run_extra_tree_model(X_train, y_train, X_valid, y_valid)\n",
    "    y_pred_valid = rankdata(y_pred_valid)/len(y_pred_valid)\n",
    "    y_pred[valid_index] = y_pred_valid.ravel()\n",
    "    \n",
    "    print(train_rmse, valid_rmse)\n",
    "\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(y_pred, y)\n",
    "coefficients = optR.coefficients()\n",
    "y_pred_opt = optR.predict(y_pred, coefficients)\n",
    "score = get_score(y, y_pred_opt)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
