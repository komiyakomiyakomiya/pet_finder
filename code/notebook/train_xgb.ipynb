{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def get_y():\n",
    "    return pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv', usecols=[target]).values.flatten()\n",
    "    \n",
    "def run_xgb_model(X_train, y_train, X_valid, y_valid,\n",
    "            categorical_features, numerical_features,\n",
    "            predictors, maxvalue_dict, fold_id):\n",
    "    d_train = xgb.DMatrix(data=X_train, label=y_train, feature_names=predictors)\n",
    "    d_valid = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=predictors)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(dtrain=d_train, evals=watchlist, params=MODEL_PARAMS_XGB, **FIT_PARAMS)\n",
    "    \n",
    "    # validation score\n",
    "    y_pred_valid = model.predict(d_valid, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    return y_pred_valid\n",
    " \n",
    "def plot_mean_feature_importances(feature_importances, max_num=50, importance_type='gain', path=None):\n",
    "    mean_gain = feature_importances[[importance_type, 'feature']].groupby('feature').mean()\n",
    "    feature_importances['mean_' + importance_type] = feature_importances['feature'].map(mean_gain[importance_type])\n",
    "\n",
    "    if path is not None:\n",
    "        data = feature_importances.sort_values('mean_'+importance_type, ascending=False).iloc[:max_num, :]\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        sns.barplot(x=importance_type, y='feature', data=data)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path)\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "def to_bins(x, borders):\n",
    "    for i in range(len(borders)):\n",
    "        if x <= borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -get_score(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [1.5, 2.0, 2.5, 3.0]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(1, 2), (1.5, 2.5), (2, 3), (2.5, 3.5)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'AdoptionSpeed'\n",
    "len_train = 14993\n",
    "len_test = 3948\n",
    "    \n",
    "    \n",
    "# ===============\n",
    "# Params\n",
    "# ===============\n",
    "seed = 777\n",
    "n_splits = 5\n",
    "np.random.seed(seed)\n",
    "\n",
    "# feature engineering\n",
    "n_components = 5\n",
    "img_size = 256\n",
    "batch_size = 256\n",
    "\n",
    "# model\n",
    "MODEL_PARAMS_XGB = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'eta': 0.01,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'device': 'gpu',\n",
    "    'silent': 1,\n",
    "}\n",
    "FIT_PARAMS = {\n",
    "    'num_boost_round': 5000,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbose_eval': 10000,\n",
    "}\n",
    "\n",
    "# define\n",
    "maxvalue_dict = {}\n",
    "categorical_features = [\n",
    "     'Breed1',\n",
    "     'Breed2',\n",
    "     'Color1',\n",
    "     'Color2',\n",
    "     'Color3',\n",
    "     'Dewormed',\n",
    "     'FurLength',\n",
    "     'Gender',\n",
    "     'Health',\n",
    "     'MaturitySize',\n",
    "     'State',\n",
    "     'Sterilized',\n",
    "     'Type',\n",
    "     'Vaccinated',\n",
    "     'Type_main_breed',\n",
    "     'BreedName_main_breed',\n",
    "     'Type_second_breed',\n",
    "     'BreedName_second_breed',\n",
    "]\n",
    "numerical_features = []\n",
    "text_features = ['Name', 'Description']\n",
    "remove = ['index', 'seq_text', 'PetID', 'Name', 'Description', 'RescuerID', 'StateName', 'annots_top_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feather.read_dataframe('X_train460.feather')\n",
    "n_train = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 63,\n",
    "    'subsample': 0.9,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'max_depth': 9,\n",
    "    'max_bin': 127,\n",
    "    'reg_alpha': 0.11,\n",
    "    'reg_lambda': 0.01,\n",
    "    'min_child_weight': 0.2,\n",
    "    'min_child_samples': 20,\n",
    "    'min_gain_to_split': 0.02,\n",
    "    'min_data_in_bin': 3,\n",
    "    'bin_construct_sample_cnt': 5000,\n",
    "    'cat_l2': 10,\n",
    "    'verbose': -1,\n",
    "    'nthread': -1,\n",
    "    'seed': 777,\n",
    "}\n",
    "bounds = [{'name': 'alpha', 'type': 'continuous', 'domain': (0, 15)},\n",
    "          {'name': 'lambda', 'type': 'continuous', 'domain': (0, 15)},\n",
    "          {'name': 'max_depth', 'type': 'discrete', 'domain': (5, 7, 10, 12, 15)},\n",
    "          {'name': 'max_leaves', 'type': 'discrete', 'domain': (10, 20, 31, 63, 127, 255)},\n",
    "          {'name': 'colsample_bylevel', 'type': 'continuous', 'domain': (0.01, 1.0)},\n",
    "          {'name': 'min_samples_leaf', 'type': 'discrete', 'domain': (10, 20, 30, 50, 60, 80, 100, 120, 150)},\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.32031\tvalid-rmse:2.30027\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[953]\ttrain-rmse:0.708063\tvalid-rmse:1.04865\n",
      "\n",
      "[0]\ttrain-rmse:2.30251\tvalid-rmse:2.37194\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[910]\ttrain-rmse:0.723786\tvalid-rmse:1.1169\n",
      "\n",
      "[0]\ttrain-rmse:2.32649\tvalid-rmse:2.27468\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[461]\ttrain-rmse:0.830407\tvalid-rmse:1.06378\n",
      "\n",
      "[0]\ttrain-rmse:2.3286\tvalid-rmse:2.26587\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[780]\ttrain-rmse:0.744626\tvalid-rmse:1.05516\n",
      "\n",
      "[0]\ttrain-rmse:2.30315\tvalid-rmse:2.36877\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[616]\ttrain-rmse:0.786248\tvalid-rmse:1.08268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL_PARAMS_XGB = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'eta': 0.01,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'max_leaves': 127,\n",
    "    'alpha': 0.1,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'device': 'gpu',\n",
    "    'silent': 1,\n",
    "}\n",
    "categorical_features = list(set(categorical_features) - set(remove))\n",
    "numerical_features = list(set(train.columns) - set(categorical_features + [target] + remove))\n",
    "predictors = categorical_features + numerical_features\n",
    "predictors = [c for c in predictors if \"gnvec\" not in c and \"glove_mag\" not in c and \"img_\" not in c]\n",
    "train = train.loc[:, ~train.columns.duplicated()]\n",
    "\n",
    "X = train.loc[:, predictors]\n",
    "y =  feather.read_dataframe('../input/X_train.feather')[\"AdoptionSpeed\"].values\n",
    "rescuer_id = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv').loc[:, 'RescuerID'].iloc[:len_train]\n",
    "\n",
    "y_pred = np.empty(len_train,)\n",
    "y_test = []\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n",
    "#for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y)):\n",
    "cv = GroupKFold(n_splits=n_splits)\n",
    "for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y=None, groups=rescuer_id)): \n",
    "    X_train = X.loc[train_index, :]\n",
    "    X_valid = X.loc[valid_index, :]\n",
    "    y_train = y[train_index]\n",
    "    y_valid = y[valid_index]\n",
    "\n",
    "    y_pred_valid = run_xgb_model(X_train, y_train, X_valid, y_valid,\n",
    "                     categorical_features, numerical_features,\n",
    "                     predictors, maxvalue_dict, fold_id)\n",
    "    y_pred[valid_index] = y_pred_valid.ravel()\n",
    "\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(y_pred, y)\n",
    "coefficients = optR.coefficients()\n",
    "y_pred_opt = optR.predict(y_pred, coefficients)\n",
    "score = get_score(y, y_pred_opt)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40797404734999587\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42707925650676515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.42707925650676515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
