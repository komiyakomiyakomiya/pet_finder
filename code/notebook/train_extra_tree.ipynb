{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def get_y():\n",
    "    return pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv', usecols=[target]).values.flatten()\n",
    "    \n",
    "def run_extra_tree_model(X_train, y_train, X_valid, y_valid, #X_test\n",
    "                        ):\n",
    "    \n",
    "    model = ExtraTreesRegressor(**Extra_Tree_PARAMS)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # train score\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "\n",
    "    # validation score\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    valid_rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "    y_pred_valid = rankdata(y_pred_valid)/len(y_pred_valid)\n",
    "\n",
    "\n",
    "    # predict test\n",
    "    #y_pred_test = model.predict(X_test)\n",
    "    #y_pred_test = rankdata(y_pred_test)/len(y_pred_test)\n",
    "\n",
    "    return y_pred_valid, train_rmse, valid_rmse\n",
    " \n",
    "\n",
    "def to_bins(x, borders):\n",
    "    for i in range(len(borders)):\n",
    "        if x <= borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "class OptimizedRounder_(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -get_score(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [1.5, 2.0, 2.5, 3.0]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(1, 2), (1.5, 2.5), (2, 3), (2.5, 3.5)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -get_score(y, X_p)\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [0.2, 0.4, 0.6, 0.8]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(0.01, 0.3), (0.15, 0.56), (0.35, 0.75), (0.6, 0.9)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n",
    "    \n",
    "class StratifiedGroupKFold():\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        fold = pd.DataFrame([X, y, groups]).T\n",
    "        fold.columns = ['X', 'y', 'groups']\n",
    "        fold['y'] = fold['y'].astype(int)\n",
    "        g = fold.groupby('groups')['y'].agg('mean').reset_index()\n",
    "        fold = fold.merge(g, how='left', on='groups', suffixes=('', '_mean'))\n",
    "        fold['y_mean'] = fold['y_mean'].apply(np.round)\n",
    "        fold['fold_id'] = 0\n",
    "        for unique_y in fold['y_mean'].unique():\n",
    "            mask = fold.y_mean==unique_y\n",
    "            selected = fold[mask].reset_index(drop=True)\n",
    "            cv = GroupKFold(n_splits=n_splits)\n",
    "            for i, (train_index, valid_index) in enumerate(cv.split(range(len(selected)), y=None, groups=selected['groups'])):\n",
    "                selected.loc[valid_index, 'fold_id'] = i\n",
    "            fold.loc[mask, 'fold_id'] = selected['fold_id'].values\n",
    "            \n",
    "        for i in range(self.n_splits):\n",
    "            indices = np.arange(len(fold))\n",
    "            train_index = indices[fold['fold_id'] != i]\n",
    "            valid_index = indices[fold['fold_id'] == i]\n",
    "            yield train_index, valid_index\n",
    "            \n",
    "def merge(train, test, path, add_cols):\n",
    "    df_ = feather.read_dataframe(path)\n",
    "    add_cols += list(df_.columns)\n",
    "    train = pd.concat((train, df_[:len_train]), axis=1)\n",
    "    test = pd.concat((test, df_[len_train:].reset_index(drop=True)), axis=1)\n",
    "    return train, test, add_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'AdoptionSpeed'\n",
    "len_train = 14993\n",
    "len_test = 3948\n",
    "    \n",
    "    \n",
    "# ===============\n",
    "# Params\n",
    "# ===============\n",
    "seed = 777\n",
    "kaeru_seed = 1337\n",
    "n_splits = 5\n",
    "np.random.seed(seed)\n",
    "\n",
    "# feature engineering\n",
    "n_components = 5\n",
    "img_size = 256\n",
    "batch_size = 256\n",
    "\n",
    "Extra_Tree_PARAMS = {\n",
    "    \"max_depth\": 5,\n",
    "    \"n_jobs\": 16,\n",
    "    \"random_state\": seed\n",
    "}\n",
    "\n",
    "# define\n",
    "maxvalue_dict = {}\n",
    "categorical_features = [\n",
    "     'Breed1',\n",
    "     'Breed2',\n",
    "     'Color1',\n",
    "     'Color2',\n",
    "     'Color3',\n",
    "     'Dewormed',\n",
    "     'FurLength',\n",
    "     'Gender',\n",
    "     'Health',\n",
    "     'MaturitySize',\n",
    "     'State',\n",
    "     'Sterilized',\n",
    "     'Type',\n",
    "     'Vaccinated',\n",
    "     'Type_main_breed',\n",
    "     'BreedName_main_breed',\n",
    "     'Type_second_breed',\n",
    "     'BreedName_second_breed',\n",
    "]\n",
    "numerical_features = []\n",
    "text_features = ['Name', 'Description']\n",
    "remove = ['index', 'seq_text', 'PetID', 'Name', 'Description', 'RescuerID', 'StateName', 'annots_top_desc', 'Description_Emb', 'Description_bow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2269\n"
     ]
    }
   ],
   "source": [
    "train = feather.read_dataframe('from_kernel/all_datav17.feather')\n",
    "test = train[len_train:]\n",
    "train = train[:len_train]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "use_cols = pd.read_csv(\"importance6.csv\")\n",
    "use_cols[\"gain\"] = use_cols[\"gain\"] / use_cols[\"gain\"].sum()\n",
    "predictors = list(use_cols[use_cols.gain>0.0002].feature) + add_cols\n",
    "print(len(predictors))\n",
    "categorical_features = [c for c in categorical_features if c in predictors]\n",
    "numerical_features = list(set(predictors) - set(categorical_features + [target] + remove))\n",
    "\n",
    "X_train = train.append(test).reset_index(drop=True).loc[:, predictors]\n",
    "for c in categorical_features:\n",
    "    X_train[c] = LabelEncoder().fit_transform(X_train[c])\n",
    "X_train.replace(np.inf, np.nan, inplace=True)\n",
    "X_train.replace(-np.inf, np.nan, inplace=True)\n",
    "X_train[numerical_features] = StandardScaler().fit_transform(X_train[numerical_features].rank())\n",
    "X_train.fillna(-999, inplace=True)\n",
    "\n",
    "X_test = X_train.iloc[len_train:]\n",
    "X = X_train.iloc[:len_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extra_Tree_PARAMS = {\n",
    "    \"max_depth\": 7,\n",
    "    \"n_estimators\": 100,\n",
    "    \"n_jobs\": 16,\n",
    "    \"random_state\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9679393763030208 1.056781568164748\n",
      "0.9493294034969463 1.1040482498800663\n",
      "0.9595882782572798 1.0907407168737013\n",
      "0.9622609477395304 1.0661513055952374\n",
      "0.9582960109455375 1.0775195178793657\n",
      "0.3932400660683706\n",
      "CPU times: user 18min 51s, sys: 1.19 s, total: 18min 52s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y =  feather.read_dataframe('../input/X_train.feather')[\"AdoptionSpeed\"].values\n",
    "rescuer_id = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv').loc[:, 'RescuerID'].iloc[:len_train]\n",
    "\n",
    "y_pred = np.empty(len_train,)\n",
    "y_test = []\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n",
    "#for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y)):\n",
    "#cv = GroupKFold(n_splits=n_splits)\n",
    "#for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y=None, groups=rescuer_id)): \n",
    "cv = StratifiedGroupKFold(n_splits=n_splits)\n",
    "for fold_id, (train_index, valid_index) in enumerate(cv.split(range(len(X)), y=y, groups=rescuer_id)): \n",
    "    X_train = X.loc[train_index, :]\n",
    "    X_valid = X.loc[valid_index, :]\n",
    "    y_train = y[train_index]\n",
    "    y_valid = y[valid_index]\n",
    "\n",
    "    y_pred_valid, train_rmse, valid_rmse = run_extra_tree_model(X_train, y_train, X_valid, y_valid)\n",
    "    y_pred_valid = rankdata(y_pred_valid)/len(y_pred_valid)\n",
    "    y_pred[valid_index] = y_pred_valid.ravel()\n",
    "    \n",
    "    print(train_rmse, valid_rmse)\n",
    "\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(y_pred, y)\n",
    "coefficients = optR.coefficients()\n",
    "y_pred_opt = optR.predict(y_pred, coefficients)\n",
    "score = get_score(y, y_pred_opt)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0606989278763572"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
