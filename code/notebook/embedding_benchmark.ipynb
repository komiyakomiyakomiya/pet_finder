{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精度向上のアプローチ\n",
    "- パラメータを変える(max features, max len, etc..) -> うまくいかなかった\n",
    "- 前処理で、embeddingできてない9000単語を読み込ませる ->3600くらいまで減って精度が上がった\n",
    "- ネットワークを変える(層を増やす)\n",
    "- 特徴を抽出する(textの長さを変える)\n",
    "- optimizerを変える, lossを変える\n",
    "- word2vecの学習をして、vctor化する\n",
    "\n",
    "best score | 0.6296086\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (130000, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")[:130000]\n",
    "print(\"Train shape : \",train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37165</th>\n",
       "      <td>07439a6aa2d79f58ea8f</td>\n",
       "      <td>What does the world look like through a Sharin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75838</th>\n",
       "      <td>0ed749144ad0a1890eb5</td>\n",
       "      <td>How does the Facebook or Google case apply wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9733</th>\n",
       "      <td>01e6a38e49d22aec6cae</td>\n",
       "      <td>How do you go no contact when you have a child...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        qid  \\\n",
       "37165  07439a6aa2d79f58ea8f   \n",
       "75838  0ed749144ad0a1890eb5   \n",
       "9733   01e6a38e49d22aec6cae   \n",
       "\n",
       "                                           question_text  target  \n",
       "37165  What does the world look like through a Sharin...       0  \n",
       "75838  How does the Facebook or Google case apply wit...       0  \n",
       "9733   How do you go no contact when you have a child...       0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "_uuid": "ba5a1b8109dee2c9fbc628d5da4a7c3447d42fb8"
   },
   "outputs": [],
   "source": [
    "##preprocessing\n",
    "dic = {\n",
    "    \"what's\": \"what is\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"isn't\":\"is not\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"don’t\": \"do not\",\n",
    "    \"i’m\": \"i am\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"won't\":\"will not\",\n",
    "    \"what’s\": \"what is\",\n",
    "    \"trump's\": \"trump is\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"can’t\": \"cannot\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"it’s\": \"it is\",\n",
    "    \"quorans\": \"quoran\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"today's\": \"todays\",\n",
    "    \"someone's\": \"someones\",\n",
    "    \"india's\": \"indias\",\n",
    "    \"one's\": \"ones\",\n",
    "    \"people's\": \"peoples\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"brexit\": \"British exit\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"doesn’t\": \"does not\",\n",
    "    \"isn’t\": \"is not\",\n",
    "    \"she's\": \"she is\",\n",
    "    'i’ve': \"i have\"\n",
    "}\n",
    "puncts = ',.\":)(-!?|;\\'$&/[]>%=#*+\\\\•~@£·_{}©^®`<→°€™›♥←×§″′Â█½à…“★”–●â►−¢²¬░¶↑±¿▾═¦║―¥▓—‹─▒：¼⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸¾Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡√'\n",
    "\n",
    "def analyze(txt):\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    for bad_word in dic:\n",
    "        if bad_word in txt:\n",
    "            txt = txt.replace(bad_word, dic[bad_word])\n",
    "            \n",
    "    for punct in puncts:\n",
    "        txt = txt.replace(punct, f' {punct} ')\n",
    "        \n",
    "    words = []\n",
    "    for word in txt.split(' '):\n",
    "        if (re.compile(r'^.*[0-9]+.*$').fullmatch(word) is not None):  # 数字が含まれるものは分割\n",
    "            for w in re.findall(r'(\\d+|\\D+)', word):\n",
    "                words.append(w)\n",
    "            continue\n",
    "        if len(word) < 1:  # 0文字（空文字）は除外\n",
    "            continue\n",
    "        words.append(word)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].map(analyze)\n",
    "\n",
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.PorterStemmer()\n",
    "lc = nltk.stem.lancaster.LancasterStemmer()\n",
    "sb = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "true = 0\n",
    "false = 0\n",
    "oov_dic = {}\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = word.lower()\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = word.upper()\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = word.capitalize()\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = ps.stem(word)\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = sb.stem(word)\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = lc.stem(word)\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    else:\n",
    "        oov_dic[word] = tokenizer.word_counts[word]\n",
    "        false += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46535 3464 0.9307186143722874\n"
     ]
    }
   ],
   "source": [
    "#43111 6888 0.8622372447448949\n",
    "print(true, false, true / (true + false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore'))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.PorterStemmer()\n",
    "lc = nltk.stem.lancaster.LancasterStemmer()\n",
    "sb = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "true = 0\n",
    "false = 0\n",
    "oov_dic = {}\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = word.lower()\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = word.upper()\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = word.capitalize()\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = ps.stem(word)\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = sb.stem(word)\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    word_ = lc.stem(word)\n",
    "    embedding_vector = embeddings_index.get(word_)\n",
    "    if embedding_vector is not None: \n",
    "        true += 1\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        continue\n",
    "    else:\n",
    "        oov_dic[word] = tokenizer.word_counts[word]\n",
    "        false += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "_uuid": "23f130e80159bb1701e449e2e91199dbfff1f1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "_uuid": "a560ab0dbab9cf6fdbdae6721ec030e300f19d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117000 samples, validate on 13000 samples\n",
      "Epoch 1/2\n",
      "117000/117000 [==============================] - 16s 141us/step - loss: 0.1406 - acc: 0.9488 - val_loss: 0.1192 - val_acc: 0.9525\n",
      "Epoch 2/2\n",
      "117000/117000 [==============================] - 14s 121us/step - loss: 0.1003 - acc: 0.9601 - val_loss: 0.1156 - val_acc: 0.9522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8fcc0ec18>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "_uuid": "ff43855164472de035a5a1d80b3db4838684701a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000/13000 [==============================] - 1s 65us/step\n",
      "F1 score at threshold 0.1 is 0.5722402597402597\n",
      "F1 score at threshold 0.11 is 0.5803497085761865\n",
      "F1 score at threshold 0.12 is 0.5858414582450191\n",
      "F1 score at threshold 0.13 is 0.5926565874730021\n",
      "F1 score at threshold 0.14 is 0.5985081175954367\n",
      "F1 score at threshold 0.15 is 0.5999101930848675\n",
      "F1 score at threshold 0.16 is 0.6029143897996357\n",
      "F1 score at threshold 0.17 is 0.6048014773776547\n",
      "F1 score at threshold 0.18 is 0.6062587575899112\n",
      "F1 score at threshold 0.19 is 0.6111375535459305\n",
      "F1 score at threshold 0.2 is 0.6160541586073501\n",
      "F1 score at threshold 0.21 is 0.6202158979391561\n",
      "F1 score at threshold 0.22 is 0.6193548387096774\n",
      "F1 score at threshold 0.23 is 0.624248496993988\n",
      "F1 score at threshold 0.24 is 0.6275303643724696\n",
      "F1 score at threshold 0.25 is 0.6294779938587514\n",
      "F1 score at threshold 0.26 is 0.6308169596690797\n",
      "F1 score at threshold 0.27 is 0.6330036439354504\n",
      "F1 score at threshold 0.28 is 0.6330708661417324\n",
      "F1 score at threshold 0.29 is 0.6366525423728813\n",
      "F1 score at threshold 0.3 is 0.6352941176470589\n",
      "F1 score at threshold 0.31 is 0.6361185983827493\n",
      "F1 score at threshold 0.32 is 0.632664134563212\n",
      "F1 score at threshold 0.33 is 0.6346258874931732\n",
      "F1 score at threshold 0.34 is 0.6328555678059536\n",
      "F1 score at threshold 0.35 is 0.6296501943364797\n",
      "F1 score at threshold 0.36 is 0.6274509803921567\n",
      "F1 score at threshold 0.37 is 0.6262053318207601\n",
      "F1 score at threshold 0.38 is 0.6262163709215798\n",
      "F1 score at threshold 0.39 is 0.6281087333718913\n",
      "F1 score at threshold 0.4 is 0.6304728546409808\n",
      "F1 score at threshold 0.41 is 0.6318261890780975\n",
      "F1 score at threshold 0.42 is 0.6311426879810539\n",
      "F1 score at threshold 0.43 is 0.6303175554224087\n",
      "F1 score at threshold 0.44 is 0.6271186440677966\n",
      "F1 score at threshold 0.45 is 0.6193390452876377\n",
      "F1 score at threshold 0.46 is 0.617283950617284\n",
      "F1 score at threshold 0.47 is 0.6101060511540861\n",
      "F1 score at threshold 0.48 is 0.6064434617814277\n",
      "F1 score at threshold 0.49 is 0.6067558954748248\n",
      "F1 score at threshold 0.5 is 0.6006430868167203\n",
      "best is 0.6366525423728813\n"
     ]
    }
   ],
   "source": [
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "f1_scores = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    score = metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))\n",
    "    f1_scores.append(score)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n",
    "print(\"best is {}\".format(np.max(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "39d4fedab4ac170863a0ee1ca3aa9be1ee58fe02"
   },
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6f3d0fd28dd2b04eaccb732b96b872e5a223d962"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "47238831a4701c8a67dc7ecb130ac1402baf7bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117000 samples, validate on 13000 samples\n",
      "Epoch 1/2\n",
      "117000/117000 [==============================] - 15s 132us/step - loss: 0.1596 - acc: 0.9469 - val_loss: 0.1337 - val_acc: 0.9489\n",
      "Epoch 2/2\n",
      "117000/117000 [==============================] - 14s 121us/step - loss: 0.0991 - acc: 0.9607 - val_loss: 0.1202 - val_acc: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa90ef890b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "b7ab4100f723ad535528865b1edc7896bce80223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000/13000 [==============================] - 1s 45us/step\n",
      "F1 score at threshold 0.1 is 0.5333333333333334\n",
      "F1 score at threshold 0.11 is 0.544535200311163\n",
      "F1 score at threshold 0.12 is 0.5495029821073558\n",
      "F1 score at threshold 0.13 is 0.5575364667747164\n",
      "F1 score at threshold 0.14 is 0.5632989690721649\n",
      "F1 score at threshold 0.15 is 0.5692695214105794\n",
      "F1 score at threshold 0.16 is 0.5731292517006803\n",
      "F1 score at threshold 0.17 is 0.5717981888745148\n",
      "F1 score at threshold 0.18 is 0.5764345159877354\n",
      "F1 score at threshold 0.19 is 0.5770084332001776\n",
      "F1 score at threshold 0.2 is 0.5800089645898701\n",
      "F1 score at threshold 0.21 is 0.5817023213472918\n",
      "F1 score at threshold 0.22 is 0.5852534562211982\n",
      "F1 score at threshold 0.23 is 0.588235294117647\n",
      "F1 score at threshold 0.24 is 0.5900094250706881\n",
      "F1 score at threshold 0.25 is 0.5920990004759638\n",
      "F1 score at threshold 0.26 is 0.5937349397590361\n",
      "F1 score at threshold 0.27 is 0.5949367088607596\n",
      "F1 score at threshold 0.28 is 0.5990147783251232\n",
      "F1 score at threshold 0.29 is 0.5991058122205662\n",
      "F1 score at threshold 0.3 is 0.6020100502512563\n",
      "F1 score at threshold 0.31 is 0.6105155691679429\n",
      "F1 score at threshold 0.32 is 0.6089644513137558\n",
      "F1 score at threshold 0.33 is 0.6093750000000001\n",
      "F1 score at threshold 0.34 is 0.6124604012671595\n",
      "F1 score at threshold 0.35 is 0.6108742004264393\n",
      "F1 score at threshold 0.36 is 0.6105717367853292\n",
      "F1 score at threshold 0.37 is 0.6139585605234461\n",
      "F1 score at threshold 0.38 is 0.6142857142857143\n",
      "F1 score at threshold 0.39 is 0.6156405990016639\n",
      "F1 score at threshold 0.4 is 0.6146067415730337\n",
      "F1 score at threshold 0.41 is 0.6149490373725934\n",
      "F1 score at threshold 0.42 is 0.6136233543216943\n",
      "F1 score at threshold 0.43 is 0.6084441873915558\n",
      "F1 score at threshold 0.44 is 0.608847497089639\n",
      "F1 score at threshold 0.45 is 0.6092560046865846\n",
      "F1 score at threshold 0.46 is 0.6060248080330773\n",
      "F1 score at threshold 0.47 is 0.6050119331742243\n",
      "F1 score at threshold 0.48 is 0.6070133010882709\n",
      "F1 score at threshold 0.49 is 0.6035430665852168\n",
      "F1 score at threshold 0.5 is 0.6043076923076923\n",
      "best is 0.6156405990016639\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "f1_scores = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    score = metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))\n",
    "    f1_scores.append(score)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n",
    "print(\"best is {}\".format(np.max(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f24f9753ff1d933fa4f75a0ba34df305632d6e93"
   },
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "25ec1aac4aedbf431a2d30de64030ce8e3203c18"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "cc188f2787ea7b98d3a40953a95a5fc09ff2764d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117000 samples, validate on 13000 samples\n",
      "Epoch 1/2\n",
      "117000/117000 [==============================] - 16s 134us/step - loss: 0.1802 - acc: 0.9365 - val_loss: 0.1257 - val_acc: 0.9512\n",
      "Epoch 2/2\n",
      "117000/117000 [==============================] - 14s 121us/step - loss: 0.1107 - acc: 0.9556 - val_loss: 0.1197 - val_acc: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa91d953128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "9abdfd1cf15257f2c0c2181a13327796e8d4584e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000/13000 [==============================] - 1s 48us/step\n",
      "F1 score at threshold 0.1 is 0.5325355272999253\n",
      "F1 score at threshold 0.11 is 0.5415549597855228\n",
      "F1 score at threshold 0.12 is 0.5472946671856753\n",
      "F1 score at threshold 0.13 is 0.55577610162763\n",
      "F1 score at threshold 0.14 is 0.5617159044921085\n",
      "F1 score at threshold 0.15 is 0.5679012345679013\n",
      "F1 score at threshold 0.16 is 0.5721476510067114\n",
      "F1 score at threshold 0.17 is 0.5765458422174841\n",
      "F1 score at threshold 0.18 is 0.5838401390095569\n",
      "F1 score at threshold 0.19 is 0.5869373345101501\n",
      "F1 score at threshold 0.2 is 0.5882878855610193\n",
      "F1 score at threshold 0.21 is 0.5924579736483416\n",
      "F1 score at threshold 0.22 is 0.5951398441082072\n",
      "F1 score at threshold 0.23 is 0.6014897579143389\n",
      "F1 score at threshold 0.24 is 0.6029203956665096\n",
      "F1 score at threshold 0.25 is 0.6038991916310034\n",
      "F1 score at threshold 0.26 is 0.6075216972034716\n",
      "F1 score at threshold 0.27 is 0.6108663729809105\n",
      "F1 score at threshold 0.28 is 0.6126305320735952\n",
      "F1 score at threshold 0.29 is 0.6130653266331657\n",
      "F1 score at threshold 0.3 is 0.6132792701469842\n",
      "F1 score at threshold 0.31 is 0.6192425793244627\n",
      "F1 score at threshold 0.32 is 0.6214396685655101\n",
      "F1 score at threshold 0.33 is 0.6224543080939948\n",
      "F1 score at threshold 0.34 is 0.624405705229794\n",
      "F1 score at threshold 0.35 is 0.624666310731447\n",
      "F1 score at threshold 0.36 is 0.6216216216216216\n",
      "F1 score at threshold 0.37 is 0.6232914160743576\n",
      "F1 score at threshold 0.38 is 0.6260387811634349\n",
      "F1 score at threshold 0.39 is 0.62296918767507\n",
      "F1 score at threshold 0.4 is 0.6233031674208144\n",
      "F1 score at threshold 0.41 is 0.6234357224118316\n",
      "F1 score at threshold 0.42 is 0.622554660529344\n",
      "F1 score at threshold 0.43 is 0.6236933797909409\n",
      "F1 score at threshold 0.44 is 0.6208920187793427\n",
      "F1 score at threshold 0.45 is 0.6201183431952663\n",
      "F1 score at threshold 0.46 is 0.6197014925373134\n",
      "F1 score at threshold 0.47 is 0.6151990349819059\n",
      "F1 score at threshold 0.48 is 0.6128440366972476\n",
      "F1 score at threshold 0.49 is 0.6143386897404203\n",
      "F1 score at threshold 0.5 is 0.6101060511540861\n",
      "best is 0.6260387811634349\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "f1_scores = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    score = metrics.f1_score(val_y, (pred_paragram_val_y>thresh).astype(int))\n",
    "    f1_scores.append(score)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n",
    "print(\"best is {}\".format(np.max(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "af087d21bdb4358701e31aded6b522accd5a8a64"
   },
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "449bc59fdc9a719aa0759ac51a4481df113604ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5489591364687741\n",
      "F1 score at threshold 0.11 is 0.5562130177514792\n",
      "F1 score at threshold 0.12 is 0.5656401944894651\n",
      "F1 score at threshold 0.13 is 0.572851805728518\n",
      "F1 score at threshold 0.14 is 0.576027107157984\n",
      "F1 score at threshold 0.15 is 0.5821152192605331\n",
      "F1 score at threshold 0.16 is 0.5881838074398249\n",
      "F1 score at threshold 0.17 is 0.5899152164212405\n",
      "F1 score at threshold 0.18 is 0.5950338600451467\n",
      "F1 score at threshold 0.19 is 0.5979760809567618\n",
      "F1 score at threshold 0.2 is 0.6019598693420438\n",
      "F1 score at threshold 0.21 is 0.6060606060606061\n",
      "F1 score at threshold 0.22 is 0.6070226070226071\n",
      "F1 score at threshold 0.23 is 0.6107317073170732\n",
      "F1 score at threshold 0.24 is 0.6132542037586548\n",
      "F1 score at threshold 0.25 is 0.616\n",
      "F1 score at threshold 0.26 is 0.6167088607594937\n",
      "F1 score at threshold 0.27 is 0.6193152784874808\n",
      "F1 score at threshold 0.28 is 0.6214396685655101\n",
      "F1 score at threshold 0.29 is 0.6227608008429927\n",
      "F1 score at threshold 0.3 is 0.6247334754797441\n",
      "F1 score at threshold 0.31 is 0.6264800861141012\n",
      "F1 score at threshold 0.32 is 0.6302566903331513\n",
      "F1 score at threshold 0.33 is 0.629955947136564\n",
      "F1 score at threshold 0.34 is 0.6291759465478842\n",
      "F1 score at threshold 0.35 is 0.6322290847838293\n",
      "F1 score at threshold 0.36 is 0.6313993174061434\n",
      "F1 score at threshold 0.37 is 0.6310344827586206\n",
      "F1 score at threshold 0.38 is 0.6287042417199302\n",
      "F1 score at threshold 0.39 is 0.6277030976037404\n",
      "F1 score at threshold 0.4 is 0.6285377358490566\n",
      "F1 score at threshold 0.41 is 0.6272401433691757\n",
      "F1 score at threshold 0.42 is 0.6243194192377496\n",
      "F1 score at threshold 0.43 is 0.620183486238532\n",
      "F1 score at threshold 0.44 is 0.6181369524984578\n",
      "F1 score at threshold 0.45 is 0.6148102053515868\n",
      "F1 score at threshold 0.46 is 0.6102337334175616\n",
      "F1 score at threshold 0.47 is 0.6101910828025479\n",
      "F1 score at threshold 0.48 is 0.6107165913492576\n",
      "F1 score at threshold 0.49 is 0.6071661237785015\n",
      "F1 score at threshold 0.5 is 0.6036988110964333\n",
      "best is 0.6322290847838293\n"
     ]
    }
   ],
   "source": [
    "pred_val_y = 0.33*pred_glove_val_y + 0.33*pred_fasttext_val_y + 0.34*pred_paragram_val_y\n",
    "f1_scores = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    score = metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))\n",
    "    f1_scores.append(score)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n",
    "print(\"best is {}\".format(np.max(f1_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6797ab73bdd5bdb8c8f6d80ec361c50a2b0f56f"
   },
   "source": [
    "## References\n",
    "https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
